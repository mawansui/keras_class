{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Класс для создания сетей глубокого обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Содержание:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Использование класса](#section1)\n",
    "2. [Установка и импорт необходимых пакетов](#section2)\n",
    "3. [Создание класса (нейросети) с заданными параметрами](#section3)\n",
    "4. [Создание и обучение модели](#section4)\n",
    "5. [Частичное обучение](#section5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Использование класса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед использованием класса нужно **установить** следующие пакеты:\n",
    "1. TensorFlow (https://www.tensorflow.org/install/)\n",
    "2. Keras (https://keras.io/#installation)\n",
    "2. h5py (https://pypi.org/project/h5py/)\n",
    "   \n",
    "`TensorFlow` – рекомендуемый бэкэнд для обучения сетей, однако возможно использовать Theano и CNTK.\n",
    "\n",
    "`Keras` - высокоуровневая абстрактная надстройка над разными бэкэндами.\n",
    "\n",
    "Пакет `h5py` нужен для сохранения модели на диск с последующим её извлечением, об этом подробнее далее в разделе с подробным описанием работы нейросети."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для использования в своём коде, нужно импортировать класс **`Keras_MLP`** из файла с говорящим названием `keras_mlp.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras_mlp import Keras_MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем нужно создать экземпляр данного класса, передав ему все необходимые параметры. Список возможных параметров:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- hidden_layer_sizes\n",
    "  - Это кортеж целых чисел, длина которого – количество слоёв всего, а значение при каждом индексе – количество нейронов в данном слое. Первый слой – входной. Его размерность, по идее, должна совпадать с размерностью входных данных. Последний слой – выходной, его размерность всегда должна совпадать с размерностью `y_train`.\n",
    "- activations\n",
    "  - Для каждого слоя нужно указать функцию активации из [всех доступных в библиотеке Keras](https://keras.io/activations/).\n",
    "- alpha\n",
    "  - float. Указывает величину параметра L2, предотвращающего оверфиттинг.\n",
    "- batch_size\n",
    "  - Указывает сколько тренировочных объектов будет показано нейросети до того, как произойдет изменение весов (можно передать int или строку `auto`, `auto` = 200)\n",
    "- learning_rate_init \n",
    "  - double. Указывает скорость обучения нейросети, контролирует размер шага при изменении весов.\n",
    "- max_iter # epochs\n",
    "  - int. Указывает, сколько раз оптимизатор будет изменять веса.\n",
    "- shuffle\n",
    "  - boolean. Указывает, перемешивать ли образцы при каждом прогоне нейросети\n",
    "- loss_function\n",
    "  - string. Указывает [функцию потерь](https://keras.io/losses/) (необходимо для компиляции нейросети).\n",
    "- metrics\n",
    "  - string or list of strings. Указывает [функцию](https://keras.io/metrics/), оценивающую качество нейросети.\n",
    "- verbose\n",
    "  - 1/0. Выводить или нет информацию о каждом прогоне нейросети в консоль.\n",
    "- early_stopping\n",
    "  - boolean. Прекращать обучение или нет, если качество предсказаний не улучшается.\n",
    "- optimizer_name\n",
    "  - string. Название выбранного оптимизатора весов из [стандартной библиотеки `Keras`](https://keras.io/optimizers/)\n",
    "- далее следуют любые параметры для выбранного оптимизатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = Keras_MLP(hidden_layer_sizes=(10, 10, 10, 42,),\n",
    "                activations = ['relu', 'relu', 'relu', 'softmax'],\n",
    "                alpha=0.00001*(2**1),\n",
    "                batch_size=200, # batch_size\n",
    "                learning_rate_init=0.001,\n",
    "                max_iter=50, # epochs - unambigous!\n",
    "                shuffle=True,\n",
    "                loss_function = \"categorical_crossentropy\",\n",
    "                metrics = ['binary_accuracy'],\n",
    "                verbose=1,\n",
    "                early_stopping=False,\n",
    "                optimizer_name=\"adam\",\n",
    "                lr=0.001,\n",
    "                beta_1 = 0.9,\n",
    "                beta_2 = 0.999,\n",
    "                epsilon=1e-08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Структура дальнейшего использования такова:\n",
    "\n",
    "Clf – это **экземпляр** класса. У него есть **метод** **`fit`**, который принимает тренировочные данные и возвращает **натренированную модель**. Эту модель затем можно **сохранить** (`model.save()`). Также у этой **модели** есть метод **`predict`**, который принимает тестовые данные и возвращает то, что предсказала. \n",
    "\n",
    "В общем виде структуру можно рассмотреть на приведенной диаграмме."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](keras_diagram.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = clf.fit(x_train, y_train)\n",
    "\n",
    "# сохраняем модель в файл\n",
    "model.save(\"any_colour_you_like.h5\")\n",
    "\n",
    "# предсказываем\n",
    "predicted_y = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Under the hood*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Установка и импорт необходимых пакетов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед использованием класса нужно **установить** следующие пакеты:\n",
    "1. TensorFlow (https://www.tensorflow.org/install/)\n",
    "2. Keras (https://keras.io/#installation)\n",
    "2. h5py (https://pypi.org/project/h5py/)\n",
    "   \n",
    "`TensorFlow` – рекомендуемый бэкэнд для обучения сетей, однако возможно использовать Theano и CNTK\n",
    "\n",
    "`Keras` - высокоуровневая абстрактная надстройка над разными бэкэндами.\n",
    "\n",
    "Пакет `h5py` нужен для сохранения модели на диск с последующим её извлечением, об этом подробнее далее"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После установки необходимо импортировать требуемые пакеты.\n",
    "\n",
    "- Всё, что импортируется из **`keras`** нужно для создания модели с заданными параметрами.\n",
    "- **`pickle`** импортируется для извлечения законсервированных данных из `.pickle`-файлов.\n",
    "- **`get_optimizer`** – это функция выбора оптимизатора весов нейросети из стандартной библиотеки `Keras`, вынесенная в отдельный файл, чтобы визуально не загружать основной код\n",
    "- Импортировать **`os.path`** нужно чтобы впоследствии проверить, есть ли на диске в рабочей папке сохранённый файл нейросети.\n",
    "- **`numpy`** импортируется для того, чтобы узнать размерность входных данных и настроить количество нейронов в первом и последнем уровне сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import optimizers, regularizers\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "import pickle\n",
    "from get_optimizer import get_optimizer\n",
    "import os.path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Создание класса с заданными параметрами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом, класс состоит из трёх функций:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Keras_MLP():\n",
    "    \n",
    "    def __init__():\n",
    "        pass\n",
    "\n",
    "    def fit():\n",
    "        pass\n",
    "    \n",
    "    def partial_fit():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`def __init__():`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот метод создаёт объект класса с заданными параметрами – ничего особенного. \n",
    "\n",
    "Правда, интересные вещи он делает в конце. В какой-то момент нейросети будет нужно задать оптимизатор весов. Однако каждый оптимизатор имеет собственные параметры; например, для того, чтобы нейросеть использовала `Adam`, ей нужно сообщить параметры `lr`, `beta_1`, `beta_2`, `epsilon` и `decay`. Однако **не всем оптимизаторам нужны именно эти параметры**, или нужны не все из них. Для того, чтобы не ограничивать себя одним оптимизатором и иметь потом возможность использовать разные их виды, сделал так, чтобы параметры именно для оптимизатора передавались в класс последними, и пары ключ-значение создавались на основании переданных значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __init__(self, \n",
    "             hidden_layer_sizes, \n",
    "             activations, \n",
    "             alpha, \n",
    "             batch_size, \n",
    "             learning_rate_init, \n",
    "             max_iter, # поменять на epochs? А то непонятно, что имеется ввиду\n",
    "             shuffle,\n",
    "             loss_function, \n",
    "             metrics, \n",
    "             verbose, \n",
    "             early_stopping,\n",
    "             optimizer_name,\n",
    "             **kwargs):\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.activations = activations\n",
    "        self.alpha = alpha\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate_init = learning_rate_init\n",
    "        self.max_iter = max_iter\n",
    "        self.shuffle = shuffle\n",
    "        self.loss_function = loss_function\n",
    "        self.metrics = metrics # = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "        self.verbose = verbose\n",
    "        self.early_stopping = early_stopping\n",
    "        self.optimizer_name = optimizer_name\n",
    "        for key, value in kwargs.items():\n",
    "          setattr(self, key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это удобно при выборе оптимизатора. Так, когда объект класса окончательно создан, в файл `get_optimizers` передаётся словарь параметров оптимизатора, откуда затем они вынимаются и присваиваются объекту выбранного оптимизатора. Этот объект затем возвращается. В том файле происходит примерно следующее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "def get_optimizer(optimizer_name, kwargs):\n",
    "    if name == \"adam\":\n",
    "\t\treturn optimizers.Adam(lr = kwargs.get('lr', 0.001),\n",
    "\t\t\t\t\t\t\t   beta_1 = kwargs.get('beta_1', 0.9),\n",
    "\t\t\t\t\t\t\t   beta_2 = kwargs.get('beta_2', 0.999),\n",
    "\t\t\t\t\t\t\t   epsilon = kwargs.get('epsilon', 0),\n",
    "\t\t\t\t\t\t\t   decay = kwargs.get('decay', 0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть, в файл передаётся название требуемого оптимизатора и набор параметров для него. Затем он выбирается и возвращается в переменную, а если оптимизатора с таким названием в стандартной библиотеке `Keras` не было найдено, возвращается дефолтный `Adam` с дефолтными же параметрами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кратко: в `__init__()` создаётся объект класса с параметрами для всей нейросети в целом и оптимизатора в частности. Параметры оптимизатора можно передавать в любом порядке, главное, **после параметра `optimizer_name`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Создание и обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`def fit(self, x_train, y_train):`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Принимает данные\n",
    "2. Создаёт модель на основании параметров, переданных в `__init__()`\n",
    "3. Обучает эту модель на переданных данных\n",
    "4. Возвращает обученную модель\n",
    "\n",
    "Подробнее:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём заготовку для модели (своеобразный шомпур, на который затем будем нанизывать слои нейронной сети)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Узнаём размерность данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_shape = int(x_train.shape[1])\n",
    "y_train_shape = int(y_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После выполняется проверка, совпадает ли заданное количество нейронов на последнем (выходном) слое нейросети с размерностью **`y_train`**. Если нет, то выводит сообщение об ошибке, а если всё в порядке, то начинает формировать нейросеть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала проходит по всем значениям количеств нейронов для каждого уровня. В случае первого слоя вместе с количеством нейронов и параметром регуляризатора явно указывается размерность входных данных (требование `Keras`). В случае всех остальных слоёв просто добавляются новые слои с заданным количеством нейронов и, после этого, слой с указанной функцией активации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index, layer_size in enumerate(self.hidden_layer_sizes):\n",
    "                if index == 0:\n",
    "                    model.add(Dense(layer_size, \n",
    "                                    input_dim=x_train_shape,\n",
    "                                    kernel_regularizer=regularizers.l2(self.alpha)))\n",
    "                    model.add(Activation(self.activations[index]))\n",
    "                else:\n",
    "                    model.add(Dense(layer_size,\n",
    "                                    kernel_regularizer=regularizers.l2(self.alpha)))\n",
    "                    model.add(Activation(self.activations[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Потом происходит выбор оптимизатора. В функцию передаётся весь словарь параметров класса, а не только часть с параметрами, относящимися непосредственно к оптимизатору. Был проведен тест скорости времени выполнения обоих вариантов (передача всего словаря и передача переменной, содержащей только пары ключ-значение, относящиеся к оптимизатору). Итог – передача всего словаря параметров класса быстрее на 2 миллисекунды, вероятно, из-за отсутствия необходимости создавать дополнительную переменную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chosen_optimizer = None \n",
    "chosen_optimizer = get_optimizer(self.optimizer_name, self.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее выполняется компиляция модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=self.loss_function, \n",
    "              optimizer=chosen_optimizer,\n",
    "              metrics=self.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводится информация о готовой к работе модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавляются колл-бэки и щепотка обратной совместимости:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Так называемые колл-бэки Keras принимает только в виде массива\n",
    "used_callbacks = []\n",
    "\n",
    "# На тот случай, если вдруг понадобится поддержка EarlyStopping,\n",
    "# код честно нашел где-то на гитхабе в обсуждениях.\n",
    "if self.early_stopping == True:\n",
    "    early_stopping_callback = EarlyStopping(monitor=\"value_loss\")\n",
    "    used_callbacks.append(early_stopping_callback)\n",
    "\n",
    "# Нужно для большей совместимости с прежним кодом\n",
    "if self.batch_size == \"auto\":\n",
    "    self.batch_size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, происходит обучение модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, \n",
    "          y_train,\n",
    "          batch_size = self.batch_size,\n",
    "          epochs = self.max_iter,\n",
    "          verbose = self.verbose,\n",
    "          callbacks = used_callbacks,\n",
    "          shuffle = self.shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И возвращается готовая модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Частичное обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В какой-то мере метод **`partial_fit()`** представляет в данном случае простую надстройку над уже описанной выше **`fit()`**. По сути, логика его работы сводится к тому, чтобы проверить, существует ли на диске в одной папке с исполняемым кодом файл сохранённой нейросети. Если есть, он открывает его и проводит обучение по вновь переданным данным. Если нет, он создает его, обучает и сохраняет вновь полученную модель в отдельный файл в той же директории. \n",
    "\n",
    "Две проблемы:\n",
    "1. Название образующегося файла захардкожено. Решение: можно добавить его как параметр в функцию `partial_fit`.\n",
    "2. **Более важно**: возможно, необходимо в `partial_fit` передавать все те же параметры, что и в обычный `fit`. Потому что вот сейчас я перечитал код и подумал, что `fit`-то выполняется в `partial_fit()`, но с какими параметрами??? Решение: передавать в `partial_fit()` те же параметры, что и в обычный `fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partial_fit(self, x_train, y_train):\n",
    "    \t# метод для обучения сети в несколько заходов\n",
    "    \t# если файл с обученной моделью уже существует,\n",
    "    \tkeras_model_filename=\"trained_keras_model.h5\"\n",
    "    \tif os.path.isfile(keras_model_filename):\n",
    "    \t\t# загрузить его\n",
    "    \t\tmodel = load_model(keras_model_filename)\n",
    "    \t\t# дообучить модель\n",
    "    \t\tmodel.fit(x_train, y_train)\n",
    "    \t\t# сохранить модель\n",
    "    \t\tmodel.save(keras_model_filename)\n",
    "    \telse:\n",
    "    \t\tmodel = self.fit(x_train, y_train)\n",
    "    \t\tmodel.save(keras_model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODOs**:\n",
    "- **(+)** переименовать max_iter в epochs\n",
    "- **(+)** переименовать hidden_layer_sizes просто в layer_sizes\n",
    "- **(+)** разобраться со входным слоем:\n",
    "  - сделать число нейронов на первом слое таким же, как количество чисел в переданном массиве\n",
    "  - почитать подробнее, для чего там нужен `input_dim` всё-таки\n",
    "- **(+)** автоматическое выставление количества нейронов на выходном слое в зависимости от входных данных\n",
    "- Обновить этот ноутбук под новую версию класса, включающую дропаут"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
